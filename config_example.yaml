# settings
project_name: "delay_prediction"
random_seed: 42
task_type: "classification"   # or "regression"

# paths
paths:
  #I kept raw data elsewhere, as it included multiple files
  raw_data_folder: "(your working directory)/data(brazil)/brazil_ecom"
  processed_data: "(your working directory)/brazil_ecom/data/brazil_ecommrce.csv"
  model_dir: "(your working directory)/brazil_ecom/models/"
  logs_dir: "(your working directory)/brazil_ecom/logs/"
  figures_dir: "(your working directory)/brazil_ecom/figures/"


# --- LOG ---
logger:
  log_file: "(your working directory)/brazil_ecom/logs/pipeline.log"
  level: INFO
  
# data settings 
data:
  target_column: "delay_bin"  # for classification
  
  num_cols: ['late_delivery', 'customer_zip_code_prefix', 'raw_price', 'freight_value',
            'num_items', 'payment_value', 'seller_id',
            'seller_zip_code_prefix', , 'seller_lat',
            'seller_lng', 'customer_lat', 'customer_lng', 'product_weight_g',
            'product_length_cm', 'product_height_cm', 'product_width_cm']

  str_cols: ['payment_type', 'product_category_name_english', 'seller_city', 'order_id', 'customer_id',
            'customer_city', 'seller_state', 'order_status', 'customer_state']

  date_cols: ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date',
       'order_delivered_customer_date', 'order_estimated_delivery_date']     

  threshold: 50  # threshold for rare categories in categorical variable product_category_name_english
  
  test_size: 0.3
  test_to_val: 0.5 # once 30% of data is test data, how much is retained for validation vs test ? (RATIO)
  min_rows: 15
  stratify: True   # only applies for classification

# #preprocessing 
# preprocessing:
#   scale_numeric: True
#   encode_catesgorical: "onehot"     # or "label"
#   impute_strategy: "median"

# bins:
#     - 0
#     - 15
#     - 60
#     - 180
  bin_labels: ["on_time", "short_delay", "long_delay"]

# training
training:
  cross_validation_folds: 5
  early_stopping_rounds: 50
  save_best_model: True

# --- Evaluation ---
evaluation:
  metrics_classification: ["accuracy", "f1", "roc_auc"]
  metrics_regression: ["r2", "rmse", "mae"]
  output_confusion_matrix: True


